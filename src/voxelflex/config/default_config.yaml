# src/voxelflex/config/default_config.yaml (Optimized)

input:
  voxel_file: input_data/voxel/mdcath_voxelized.hdf5
  aggregated_rmsf_file: input_data/rmsf/aggregated_rmsf_all_temps.csv
  train_split_file: input_data/train_domains.txt
  val_split_file: input_data/val_domains.txt
  test_split_file: input_data/test_domains.txt # Optional
  max_domains: null # Optional limit

data:
  # Directory to save/load master sample list
  processed_dir: input_data/processed/
  # Base name for the master samples file saved by preprocess
  master_samples_file: "master_samples.parquet" # Default to Parquet
  # Filename (relative to output.models_dir) for temp scaling params
  temp_scaling_params_file: "temp_scaling_params.json"
  # Cache settings (new)
  domain_cache_mb: 2000  # Conservative 2GB initial cache size
  monitor_memory: true    # Enable memory monitoring

output:
  base_dir: outputs/
  run_name: "voxelflex_run_{timestamp}"
  log_file: voxelflex.log

model:
  architecture: multipath_rmsf_net
  input_channels: 5
  # Voxel spatial dimensions (needed by VoxelDataset)
  voxel_depth: 21
  voxel_height: 21
  voxel_width: 21
  # --- Arch Specific ---
  densenet: { growth_rate: 16, block_config: [4, 4, 4], num_init_features: 32, bn_size: 4 }
  channel_growth_rate: 1.5
  num_residual_blocks: 3
  base_filters: 32
  dropout_rate: 0.3

training:
  batch_size: 256 # Batch size for DataLoader during TRAINING
  num_epochs: 10
  learning_rate: 0.0005
  weight_decay: 1e-4
  seed: 42
  num_workers: 4  # REDUCED from 12 to reduce I/O contention
  pin_memory: true
  prefetch_factor: 6  # INCREASED from 4 to compensate for fewer workers
  # persistent_workers: true  # Now enabled for HDF5 connection reuse
  resume_checkpoint: null
  save_best_metric: "val_loss"
  save_best_mode: "max"
  checkpoint_interval: 5
  gradient_clipping: { enabled: true, max_norm: 1.0 }
  mixed_precision: { enabled: true }
  # New option for gradient accumulation
  gradient_accumulation_steps: 1  # Increase to effectively increase batch size
  scheduler: { type: reduce_on_plateau, monitor_metric: "val_loss", mode: "max", patience: 5, factor: 0.5, min_lr: 1e-07, threshold: 0.001 }
  early_stopping: { enabled: true, patience: 10, monitor_metric: "val_loss", mode: "max", min_delta: 0.001 }

prediction:
  batch_size: 256 # Batch size for predict/evaluate (on-demand HDF5 loading)

evaluation:
  calculate_stratified_metrics: true
  calculate_permutation_importance: true
  sasa_bins: [0.0, 0.1, 0.4, 1.01]
  permutation_n_repeats: 5

logging:
  level: INFO
  console_level: INFO
  file_level: DEBUG
  show_progress_bars: true
  # New options for performance monitoring
  log_timing: true
  log_memory_usage: true
  log_cache_stats: true

visualization:
  plot_loss: true
  plot_correlation: true
  plot_predictions: true
  plot_density_scatter: true
  plot_error_distribution: true
  plot_residue_type_analysis: true
  plot_sasa_error_analysis: true
  plot_ss_error_analysis: true
  plot_amino_acid_performance: false
  save_format: png
  dpi: 150
  max_scatter_points: 1000
  save_plot_data: true

system_utilization:
  detect_cores: true
  adjust_for_gpu: true


  